{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU activa: True \n",
      "Cantidad de GPs 2\n",
      "Se cargaron los datos correctamente\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "\n",
    "total_fase = 2 \n",
    "save_model = True\n",
    "load_model = False\n",
    "device = \"cuda\"\n",
    "data_dir = \"../data\" \n",
    "batch_size = 32\n",
    "\n",
    "print(\"GPU activa:\", torch.cuda.is_available(), \"\\nCantidad de GPs\", torch.cuda.device_count())\n",
    "#------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Conjunto de datos MNIST\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root=data_dir,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "eval_data = torchvision.datasets.MNIST(\n",
    "    root=data_dir,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "num_classes = 10  \n",
    "class_dataloaders = []\n",
    "\n",
    "# Itera sobre cada clase y crea un DataLoader para esa clase\n",
    "for class_idx in range(num_classes):\n",
    "    # Obtén los índices para la clase actual\n",
    "    class_indices = [i for i in range(len(train_data)) if train_data.targets[i] == class_idx]\n",
    "    \n",
    "    # Subconjunto de datos para la clase actual\n",
    "    class_subset = Subset(train_data, class_indices)\n",
    "    \n",
    "    # DataLoader para la clase actual\n",
    "    class_dataloader = DataLoader(class_subset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Agrega el DataLoader al listado\n",
    "    class_dataloaders.append(class_dataloader)\n",
    "\n",
    "\n",
    "eval_dataloader = DataLoader(eval_data, batch_size=10000, shuffle=True)\n",
    "print(\"Se cargaron los datos correctamente\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emendezc/miniconda3/envs/cil/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/emendezc/miniconda3/envs/cil/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractor(dataloader, model):\n",
    "    model.eval()\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            # Obtener las características (vectores de características) del modelo\n",
    "            features = model(X)\n",
    "            all_features.append(features.cpu())\n",
    "            all_labels.append(y.cpu())\n",
    "\n",
    "    # Concatenar todas las características y etiquetas\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    \n",
    "    return all_features, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m X, y \u001b[39min\u001b[39;00m class_dataloader[\u001b[39m0\u001b[39;49m]:\n\u001b[1;32m      2\u001b[0m     \u001b[39mprint\u001b[39m(X)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "for X, y in class_dataloader[0]:\n",
    "    print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m embedding \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m()\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m data_i \u001b[39min\u001b[39;00m class_dataloader:\n\u001b[0;32m----> 4\u001b[0m     features, labels \u001b[39m=\u001b[39m extractor(data_i, model)\n\u001b[1;32m      5\u001b[0m     embedding\u001b[39m.\u001b[39mappend(features, labels)\n",
      "Cell \u001b[0;32mIn[25], line 7\u001b[0m, in \u001b[0;36mextractor\u001b[0;34m(dataloader, model)\u001b[0m\n\u001b[1;32m      4\u001b[0m all_labels \u001b[39m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> 7\u001b[0m     \u001b[39mfor\u001b[39;00m X, y \u001b[39min\u001b[39;00m dataloader:\n\u001b[1;32m      8\u001b[0m         X, y \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(device), y\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m         \u001b[39m# Obtener las características (vectores de características) del modelo\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "embedding = list()\n",
    "for data_i in class_dataloader:\n",
    "    features, labels = extractor(data_i, model)\n",
    "    embedding.append(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prototype():\n",
    "    p_i= [i for i in ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "learning_rate = 1e-3\n",
    "# Initialize the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn, t):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    tarjet_prediction = []  # Lista para almacenar las etiquetas reales y predicciones\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "            # Guardar la etiqueta real y la predicción en la lista de tuplas\n",
    "            tarjet_prediction.extend(list(zip(y.cpu().numpy(), pred.argmax(1).cpu().numpy())))\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    log_accuracy_loss.append((100*correct, test_loss))\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    \n",
    "    \n",
    "    # Definir la ruta del archivo\n",
    "    directorio= 'logs'\n",
    "    if not os.path.exists(directorio):\n",
    "        os.makedirs(directorio)\n",
    "    with open(f'logs/epoch_{i}_CC_{t}.txt', 'w') as archivo:\n",
    "            # Escribe el valor de la variable en el archivo\n",
    "            archivo.write(str(tarjet_prediction))\n",
    "    print(f'El valor prediciones se ha guardado en el archivo.txt')\n",
    "    \n",
    "\n",
    "epochs = 30\n",
    "\n",
    "data_1 = train_0_to_4_dataloader\n",
    "data_2 = train_5_to_9_dataloader\n",
    "log_accuracy_loss = []\n",
    "for t in range(total_fase):\n",
    "    print(\"*\" *200)\n",
    "    print(f\"Etapa {t}\")\n",
    "\n",
    "\n",
    "    for i in range(epochs):\n",
    "        if t == 0:\n",
    "            print(f\"Epoch {i+1}\\n-------------------------------\")\n",
    "            train_loop(data_1, model, loss_fn, optimizer)\n",
    "            test_loop(eval_dataloader, model, loss_fn, t)\n",
    "        elif t == 1:\n",
    "            print(f\"Epoch {i+1}\\n-------------------------------\")\n",
    "            train_loop(data_2, model, loss_fn, optimizer)\n",
    "            test_loop(eval_dataloader, model, loss_fn, t)\n",
    "\n",
    "    if save_model: torch.save(model.state_dict(), f'Fase_{t}_cifar10.pth'); print(f\"Se guardo el modelo en la Fase:{t}_cifar10\")\n",
    "\n",
    "with open(f'logs/log_accuracy_loss_cifar10.txt', 'w') as archivo:\n",
    "        archivo.write(str(log_accuracy_loss))\n",
    "\n",
    "print(f'Se guardo correctamente el acurracy')\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
